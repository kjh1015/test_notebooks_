{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatLiteLLM\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = ChatLiteLLM(model=\"gpt-4o-mini\").bind(logprobs=True) \n",
    "# This does not work\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model=\"gpt-4o-mini\").bind(logprobs=True)\n",
    "# Only OpenAI works for logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002E43E695B50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002E43E4B6D20>, root_client=<openai.OpenAI object at 0x000002E43E687170>, root_async_client=<openai.AsyncOpenAI object at 0x000002E43E695B80>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'logprobs': True}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    HumanMessage(\n",
    "        content=\"what model are you\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = chat.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'token': 'I', 'bytes': [73], 'logprob': -0.038042292, 'top_logprobs': []},\n",
       " {'token': ' am',\n",
       "  'bytes': [32, 97, 109],\n",
       "  'logprob': -0.038042065,\n",
       "  'top_logprobs': []},\n",
       " {'token': ' based',\n",
       "  'bytes': [32, 98, 97, 115, 101, 100],\n",
       "  'logprob': -0.000698496,\n",
       "  'top_logprobs': []},\n",
       " {'token': ' on', 'bytes': [32, 111, 110], 'logprob': 0.0, 'top_logprobs': []},\n",
       " {'token': ' Open',\n",
       "  'bytes': [32, 79, 112, 101, 110],\n",
       "  'logprob': -0.014165984,\n",
       "  'top_logprobs': []}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg.response_metadata[\"logprobs\"][\"content\"][:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str, ..., \"The setup of the joke\"]\n",
    "\n",
    "    # Alternatively, we could have specified setup as:\n",
    "\n",
    "    # setup: str                    # no default, no description\n",
    "    # setup: Annotated[str, ...]    # no default, no description\n",
    "    # setup: Annotated[str, \"foo\"]  # default, no description\n",
    "\n",
    "    punchline: Annotated[str, ..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None, \"How funny the joke is, from 1 to 10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_chat = chat.with_structured_output(Joke)\n",
    "response = structured_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'What kind of model am I?',\n",
       " 'punchline': \"I'm an AI model, but I still can't find my way around a runway!\",\n",
       " 'rating': 6}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response # If I force the llm to return a structured output, it does not return the logprobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I am based on OpenAI's GPT-3 model. My training includes a wide range of information up until October 2021, and I can assist with various topics, answer questions, and engage in conversation. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 11, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_39a40c96a0', 'finish_reason': 'stop', 'logprobs': {'content': [{'token': 'I', 'bytes': [73], 'logprob': -0.038042292, 'top_logprobs': []}, {'token': ' am', 'bytes': [32, 97, 109], 'logprob': -0.038042065, 'top_logprobs': []}, {'token': ' based', 'bytes': [32, 98, 97, 115, 101, 100], 'logprob': -0.000698496, 'top_logprobs': []}, {'token': ' on', 'bytes': [32, 111, 110], 'logprob': 0.0, 'top_logprobs': []}, {'token': ' Open', 'bytes': [32, 79, 112, 101, 110], 'logprob': -0.014165984, 'top_logprobs': []}, {'token': 'AI', 'bytes': [65, 73], 'logprob': 0.0, 'top_logprobs': []}, {'token': \"'s\", 'bytes': [39, 115], 'logprob': -0.00015848507, 'top_logprobs': []}, {'token': ' GPT', 'bytes': [32, 71, 80, 84], 'logprob': -0.0012680899, 'top_logprobs': []}, {'token': '-', 'bytes': [45], 'logprob': -9.4914985e-06, 'top_logprobs': []}, {'token': '3', 'bytes': [51], 'logprob': -0.029750485, 'top_logprobs': []}, {'token': ' model', 'bytes': [32, 109, 111, 100, 101, 108], 'logprob': -0.26536855, 'top_logprobs': []}, {'token': '.', 'bytes': [46], 'logprob': -1.704466, 'top_logprobs': []}, {'token': ' My', 'bytes': [32, 77, 121], 'logprob': -1.7841849, 'top_logprobs': []}, {'token': ' training', 'bytes': [32, 116, 114, 97, 105, 110, 105, 110, 103], 'logprob': -1.0181562, 'top_logprobs': []}, {'token': ' includes', 'bytes': [32, 105, 110, 99, 108, 117, 100, 101, 115], 'logprob': -0.19740032, 'top_logprobs': []}, {'token': ' a', 'bytes': [32, 97], 'logprob': -0.029541142, 'top_logprobs': []}, {'token': ' wide', 'bytes': [32, 119, 105, 100, 101], 'logprob': -0.22659199, 'top_logprobs': []}, {'token': ' range', 'bytes': [32, 114, 97, 110, 103, 101], 'logprob': -0.059345253, 'top_logprobs': []}, {'token': ' of', 'bytes': [32, 111, 102], 'logprob': -3.1281633e-07, 'top_logprobs': []}, {'token': ' information', 'bytes': [32, 105, 110, 102, 111, 114, 109, 97, 116, 105, 111, 110], 'logprob': -1.0771828, 'top_logprobs': []}, {'token': ' up', 'bytes': [32, 117, 112], 'logprob': -0.3156568, 'top_logprobs': []}, {'token': ' until', 'bytes': [32, 117, 110, 116, 105, 108], 'logprob': -0.4287373, 'top_logprobs': []}, {'token': ' October', 'bytes': [32, 79, 99, 116, 111, 98, 101, 114], 'logprob': -0.0028265081, 'top_logprobs': []}, {'token': ' ', 'bytes': [32], 'logprob': 0.0, 'top_logprobs': []}, {'token': '202', 'bytes': [50, 48, 50], 'logprob': 0.0, 'top_logprobs': []}, {'token': '1', 'bytes': [49], 'logprob': -0.16022535, 'top_logprobs': []}, {'token': ',', 'bytes': [44], 'logprob': -0.3139518, 'top_logprobs': []}, {'token': ' and', 'bytes': [32, 97, 110, 100], 'logprob': -0.5335931, 'top_logprobs': []}, {'token': ' I', 'bytes': [32, 73], 'logprob': -0.3280174, 'top_logprobs': []}, {'token': ' can', 'bytes': [32, 99, 97, 110], 'logprob': -0.1408378, 'top_logprobs': []}, {'token': ' assist', 'bytes': [32, 97, 115, 115, 105, 115, 116], 'logprob': -0.03804287, 'top_logprobs': []}, {'token': ' with', 'bytes': [32, 119, 105, 116, 104], 'logprob': -0.008793489, 'top_logprobs': []}, {'token': ' various', 'bytes': [32, 118, 97, 114, 105, 111, 117, 115], 'logprob': -0.6694409, 'top_logprobs': []}, {'token': ' topics', 'bytes': [32, 116, 111, 112, 105, 99, 115], 'logprob': -0.37015533, 'top_logprobs': []}, {'token': ',', 'bytes': [44], 'logprob': -0.35437018, 'top_logprobs': []}, {'token': ' answer', 'bytes': [32, 97, 110, 115, 119, 101, 114], 'logprob': -0.0638258, 'top_logprobs': []}, {'token': ' questions', 'bytes': [32, 113, 117, 101, 115, 116, 105, 111, 110, 115], 'logprob': -2.4034345e-05, 'top_logprobs': []}, {'token': ',', 'bytes': [44], 'logprob': -7.89631e-07, 'top_logprobs': []}, {'token': ' and', 'bytes': [32, 97, 110, 100], 'logprob': -0.03840349, 'top_logprobs': []}, {'token': ' engage', 'bytes': [32, 101, 110, 103, 97, 103, 101], 'logprob': -0.7528877, 'top_logprobs': []}, {'token': ' in', 'bytes': [32, 105, 110], 'logprob': -4.3202e-07, 'top_logprobs': []}, {'token': ' conversation', 'bytes': [32, 99, 111, 110, 118, 101, 114, 115, 97, 116, 105, 111, 110], 'logprob': -0.24995726, 'top_logprobs': []}, {'token': '.', 'bytes': [46], 'logprob': -0.01042677, 'top_logprobs': []}, {'token': ' How', 'bytes': [32, 72, 111, 119], 'logprob': -0.4356816, 'top_logprobs': []}, {'token': ' can', 'bytes': [32, 99, 97, 110], 'logprob': -0.0031779523, 'top_logprobs': []}, {'token': ' I', 'bytes': [32, 73], 'logprob': 0.0, 'top_logprobs': []}, {'token': ' help', 'bytes': [32, 104, 101, 108, 112], 'logprob': -0.02975118, 'top_logprobs': []}, {'token': ' you', 'bytes': [32, 121, 111, 117], 'logprob': 0.0, 'top_logprobs': []}, {'token': ' today', 'bytes': [32, 116, 111, 100, 97, 121], 'logprob': -4.3202e-07, 'top_logprobs': []}, {'token': '?', 'bytes': [63], 'logprob': -7.9418505e-06, 'top_logprobs': []}], 'refusal': None}}, id='run-f62ae861-3798-46dc-8e34-cf5d0b69e177-0', usage_metadata={'input_tokens': 11, 'output_tokens': 50, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
