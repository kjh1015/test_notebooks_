{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# First create a .env file with:\\nOPENAI_API_KEY=your-api-key-here\\n\\n# Then in your notebook:\\nworkflow = LLMWorkflow()\\n\\n# Test single interaction\\nresult = workflow.run(\"Hi, I\\'m Alex and I\\'m here to learn.\")\\nprint(result[\"messages\"][-1].content)\\n\\n# Or run interactive loop\\nwhile result[\"session_active\"]:\\n    user_input = input(\"Your response: \")\\n    result = workflow.run(user_input)\\n    print(result[\"messages\"][-1].content)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Union, TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define state schema\n",
    "class State(TypedDict):\n",
    "    messages: List[Union[HumanMessage, AIMessage]]\n",
    "    attention_score: int\n",
    "    consecutive_wrong: int\n",
    "    user_verified: bool\n",
    "    next: str\n",
    "    iteration: int\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7,\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "class LLMWorkflow:\n",
    "    def __init__(self):\n",
    "        self.workflow = self._create_workflow()\n",
    "    \n",
    "    @staticmethod    \n",
    "    def end_function(state: State) -> bool:\n",
    "        \"\"\"Determine if workflow should end\"\"\"\n",
    "        conditions = [\n",
    "            state.get('attention_score', 0) <= 0,\n",
    "            state.get('consecutive_wrong', 0) >= 3,\n",
    "            state.get('iteration', 0) >= 10,  # Maximum iterations\n",
    "            state.get('next') == 'end'\n",
    "        ]\n",
    "        return any(conditions)\n",
    "        \n",
    "    def _create_workflow(self):\n",
    "        def greeting(state: State) -> Dict:\n",
    "            if 'messages' not in state:\n",
    "                state['messages'] = []\n",
    "                \n",
    "            state['messages'].append(AIMessage(content=\n",
    "                \"Welcome! I'm an AI assistant ready to help you. \"\n",
    "                \"Before we begin, please tell me your name and why you're here today.\"\n",
    "            ))\n",
    "            state['attention_score'] = 100\n",
    "            state['consecutive_wrong'] = 0\n",
    "            state['user_verified'] = False\n",
    "            state['next'] = 'verify'\n",
    "            state['iteration'] = 0\n",
    "            return state\n",
    "\n",
    "        def verify_user(state: State) -> Dict:\n",
    "            state['iteration'] = state.get('iteration', 0) + 1\n",
    "            last_message = state['messages'][-1].content if state['messages'] else \"\"\n",
    "            \n",
    "            response = llm.invoke(\"Is this response genuine and focused? Answer PASS or FAIL: \" + last_message)\n",
    "            \n",
    "            if \"FAIL\" in response.content.upper():\n",
    "                state['attention_score'] = state.get('attention_score', 100) - 20\n",
    "                state['messages'].append(AIMessage(content=\n",
    "                    \"I notice some concerns. Could you please respond more naturally?\"\n",
    "                ))\n",
    "            else:\n",
    "                state['user_verified'] = True\n",
    "                state['messages'].append(AIMessage(content=\n",
    "                    \"Great! You seem ready to proceed. Let's continue.\"\n",
    "                ))\n",
    "                \n",
    "            if self.end_function(state):\n",
    "                state['next'] = 'end'\n",
    "                state['messages'].append(AIMessage(content=\n",
    "                    \"Let's conclude our session here. Thank you for participating!\"\n",
    "                ))\n",
    "            else:\n",
    "                state['next'] = 'process'\n",
    "            return state\n",
    "\n",
    "        def process_response(state: State) -> Dict:\n",
    "            state['iteration'] = state.get('iteration', 0) + 1\n",
    "            last_message = state['messages'][-1].content if state['messages'] else \"\"\n",
    "            \n",
    "            response = llm.invoke(\"Does this show understanding? Answer CORRECT or INCORRECT: \" + last_message)\n",
    "            \n",
    "            if \"CORRECT\" in response.content.upper():\n",
    "                state['consecutive_wrong'] = 0\n",
    "                state['messages'].append(AIMessage(content=\n",
    "                    \"Excellent! Your response shows good understanding. Let's continue.\"\n",
    "                ))\n",
    "            else:\n",
    "                state['consecutive_wrong'] = state.get('consecutive_wrong', 0) + 1\n",
    "                state['messages'].append(AIMessage(content=\n",
    "                    f\"That's not quite right. This is attempt {state['consecutive_wrong']} out of 3.\"\n",
    "                ))\n",
    "                \n",
    "            if self.end_function(state):\n",
    "                state['next'] = 'end'\n",
    "                state['messages'].append(AIMessage(content=\n",
    "                    \"Let's conclude our session here. Thank you for participating!\"\n",
    "                ))\n",
    "            else:\n",
    "                state['next'] = 'verify'\n",
    "            return state\n",
    "\n",
    "        # Create workflow\n",
    "        workflow = StateGraph(State)\n",
    "        \n",
    "        # Add nodes\n",
    "        workflow.add_node(\"greeting\", greeting)\n",
    "        workflow.add_node(\"verify\", verify_user)\n",
    "        workflow.add_node(\"process\", process_response)\n",
    "\n",
    "        # Add conditional edges\n",
    "        def router(state: State) -> str:\n",
    "            if self.end_function(state):\n",
    "                return END\n",
    "            return state[\"next\"]\n",
    "\n",
    "        for node in [\"greeting\", \"verify\", \"process\"]:\n",
    "            workflow.add_conditional_edges(\n",
    "                node,\n",
    "                router\n",
    "            )\n",
    "\n",
    "        # Set entry point\n",
    "        workflow.set_entry_point(\"greeting\")\n",
    "        \n",
    "        return workflow.compile()\n",
    "\n",
    "    def run(self, user_input: str) -> Dict:\n",
    "        \"\"\"Run the workflow with user input\"\"\"\n",
    "        initial_state: State = {\n",
    "            \"messages\": [HumanMessage(content=user_input)],\n",
    "            \"attention_score\": 100,\n",
    "            \"consecutive_wrong\": 0,\n",
    "            \"user_verified\": False,\n",
    "            \"next\": \"greeting\",\n",
    "            \"iteration\": 0\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            final_state = self.workflow.invoke(initial_state)\n",
    "            return {\n",
    "                \"messages\": final_state[\"messages\"],\n",
    "                \"attention_score\": final_state.get(\"attention_score\", 0),\n",
    "                \"session_active\": not self.end_function(final_state)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing workflow: {str(e)}\")\n",
    "            return {\n",
    "                \"messages\": [AIMessage(content=\"Sorry, there was an error processing your input.\")],\n",
    "                \"attention_score\": 0,\n",
    "                \"session_active\": False\n",
    "            }\n",
    "\n",
    "# Example usage in Jupyter notebook:\n",
    "\"\"\"\n",
    "# First create a .env file with:\n",
    "OPENAI_API_KEY=your-api-key-here\n",
    "\n",
    "# Then in your notebook:\n",
    "workflow = LLMWorkflow()\n",
    "\n",
    "# Test single interaction\n",
    "result = workflow.run(\"Hi, I'm Alex and I'm here to learn.\")\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n",
    "# Or run interactive loop\n",
    "while result[\"session_active\"]:\n",
    "    user_input = input(\"Your response: \")\n",
    "    result = workflow.run(user_input)\n",
    "    print(result[\"messages\"][-1].content)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's conclude our session here. Thank you for participating!\n"
     ]
    }
   ],
   "source": [
    "workflow = LLMWorkflow()\n",
    "\n",
    "# Test with a single interaction\n",
    "result = workflow.run(\"Hi, I'm Alex and I'm here to learn.\")\n",
    "print(result[\"messages\"][-1].content)\n",
    "\n",
    "# Or run an interactive loop\n",
    "while result[\"session_active\"]:\n",
    "    user_input = input(\"Your response: \")\n",
    "    result = workflow.run(user_input)\n",
    "    print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
